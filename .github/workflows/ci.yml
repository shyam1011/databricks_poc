name: Upload WHL & Run Databricks Job

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    env:
      DATABRICKS_HOST: https://adb-4477823463141297.17.azuredatabricks.net
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -

      - name: Install dependencies
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          poetry install

      - name: Build .whl file
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          poetry build --format wheel

      - name: Install Databricks CLI
        run: |
          pip install databricks-cli

      - name: Upload .whl file to DBFS at /FileStore/whl_poc/
        run: |
          WHL_FILE=$(ls dist/*.whl | head -n 1)
          WHL_NAME=$(basename "$WHL_FILE")
          echo "Uploading $WHL_NAME to DBFS at /FileStore/whl_poc/"
          databricks fs cp "$WHL_FILE" "dbfs:/FileStore/whl_poc/$WHL_NAME" --overwrite

      - name: Deploy Databricks Job
        run: |
          pip install databricks-sdk
          python deploy_job.py
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

      - name: Trigger Databricks Job
        run: python trigger_job.py
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
