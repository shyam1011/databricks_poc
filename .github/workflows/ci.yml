name: Upload WHL & Run Databricks Job

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_HTTP_PATH: ${{ secrets.DATABRICKS_HTTP_PATH }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -

      - name: Install dependencies
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          poetry install
      - name: Validate Databricks secrets
        run: |
          echo "üîç Validating Databricks secrets..."

          if [ -z "${DATABRICKS_HOST}" ]; then
            echo "‚ùå DATABRICKS_HOST is not set"; exit 1;
          fi
          if [ -z "${DATABRICKS_TOKEN}" ]; then
            echo "‚ùå DATABRICKS_TOKEN is not set"; exit 1;
          fi
          if [ -z "${DATABRICKS_HTTP_PATH}" ]; then
            echo "‚ùå DATABRICKS_HTTP_PATH is not set"; exit 1;
          fi

          echo "‚úÖ All Databricks secrets found"
      - name: Build .whl file
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          poetry build --format wheel

      - name: Install Databricks CLI
        run: |
          pip install databricks-cli

      - name: Upload .whl file to DBFS at /FileStore/whl_poc/
        run: |
          WHL_FILE=$(ls dist/*.whl | head -n 1)
          WHL_NAME=$(basename "$WHL_FILE")
          echo "Uploading $WHL_NAME to DBFS at /FileStore/whl_poc/"
          databricks fs cp "$WHL_FILE" "dbfs:/FileStore/whl_poc/$WHL_NAME" --overwrite

      - name: Deploy Databricks Job
        env:
            DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
            DATABRICKS_HTTP_PATH: ${{ secrets.DATABRICKS_HTTP_PATH }}
            DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          pip install databricks-sdk
          python deploy_job.py
        

      - name: Trigger Databricks Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: python trigger_job.py
        
